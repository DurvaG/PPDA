{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decf2114",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "decf2114",
    "outputId": "f1654033-92d1-40da-cef9-f49d360b88be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\devan\\anaconda3\\lib\\site-packages (2.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\devan\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.11.23)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.20.3)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\devan\\anaconda3\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\devan\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\devan\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\devan\\anaconda3\\lib\\site-packages (1.1.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\devan\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scipy in c:\\users\\devan\\anaconda3\\lib\\site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\devan\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from catboost) (1.3.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from catboost) (3.6.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\devan\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (1.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (9.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\devan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\devan\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install xgboost\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28c23b4",
   "metadata": {
    "id": "a28c23b4"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline \n",
    "\n",
    "## Models\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## Model evaluators\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74129ff4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74129ff4",
    "outputId": "08520be8-4c78-4da7-e991-7484a3d3c69a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(83000, 53)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"TrainingData.csv\")\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb1fa41",
   "metadata": {
    "id": "1cb1fa41"
   },
   "outputs": [],
   "source": [
    "train_df1 = train_df.drop(['mvar47','application_key', 'default_ind'], axis=1)\n",
    "\n",
    "train_df2 = train_df1.replace(to_replace =\"[a-zA-Z]+\", value = np.nan, regex = True)\n",
    "train_df2 = train_df2.astype('float')\n",
    "train_df2 = pd.concat([train_df2, train_df['mvar47']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mHqnuvOGhr6G",
   "metadata": {
    "id": "mHqnuvOGhr6G"
   },
   "outputs": [],
   "source": [
    "# one hot encoding \n",
    "train_df2 = pd.get_dummies(train_df2, columns=['mvar47'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888ba72",
   "metadata": {
    "id": "0888ba72"
   },
   "source": [
    "# **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16HffDNWw7rK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16HffDNWw7rK",
    "outputId": "e0126afd-7640-43ec-c590-0f2c453ebf88"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"testX.csv\")\n",
    "test_df1 = test_df.drop(['mvar47'], axis=1)\n",
    "test_df2 = test_df1.replace(to_replace =\"[a-zA-Z]+\", value = np.nan, regex = True)\n",
    "test_df2 = test_df2.astype('float')\n",
    "test_df2 = pd.concat([test_df2, test_df['mvar47']], axis=1)\n",
    "test_df2 = pd.get_dummies(test_df2, columns=['mvar47'])\n",
    "test_df2 = test_df2.drop('application_key', axis=1)\n",
    "\n",
    "df_list = [test_df2, train_df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Wv7iYMv8inTs",
   "metadata": {
    "id": "Wv7iYMv8inTs"
   },
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "  df['mvar3'] = (1+df['mvar3'])*(1+df['mvar4'])*(1+df['mvar5'])\n",
    "  df['mvar7'] = df['mvar7'] + df['mvar8']\n",
    "  mvar161718 = (df['mvar16'].add(df['mvar17'], fill_value=0)).add(df['mvar18'], fill_value=0)\n",
    "  df['mvar16'] = mvar161718\n",
    "  df['mvar26'] = (df['mvar26']+df['mvar27'])/2/365\n",
    "  df['mvar35'] = df['mvar35'] + df['mvar34']\n",
    "  df['mvar45'] = (df['mvar45'] + df['mvar46'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "z6jZHhJ7tuER",
   "metadata": {
    "id": "z6jZHhJ7tuER"
   },
   "outputs": [],
   "source": [
    "#Since we have combined certain columns, we need to drop those which are already considered in the combination.\n",
    "\n",
    "train_data = train_df2.drop(['mvar4', 'mvar5', 'mvar8', 'mvar17', 'mvar18', 'mvar27', 'mvar34', 'mvar46', 'mvar48', 'mvar49'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fcab637",
   "metadata": {
    "id": "4fcab637"
   },
   "outputs": [],
   "source": [
    "# dropping columns which have > 70% NULL values\n",
    "train_data1 = train_data.drop(['mvar31', 'mvar40'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a331c",
   "metadata": {
    "id": "de1a331c"
   },
   "source": [
    "**Scaling and normalisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94170c28",
   "metadata": {
    "id": "94170c28"
   },
   "source": [
    "it is necessary because we will be using knn imputation as well as SMOTE for oversampling, which is also based on KNN methodology. For this reason, we need to scale the data so that higher magnitudes don't led to formation of clusters when using KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1KUaXyITfxlx",
   "metadata": {
    "id": "1KUaXyITfxlx"
   },
   "source": [
    "*Standardization*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360a71f0",
   "metadata": {
    "id": "360a71f0"
   },
   "outputs": [],
   "source": [
    "# importing sklearn StandardScaler class which is for Standardization\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sc = StandardScaler() # creating an instance of the class object\n",
    "#df_scaled = pd.DataFrame(sc.fit_transform(train_df4), columns=train_df4.columns)  #fit and transforming StandardScaler the dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fxYk3rTMh2dt",
   "metadata": {
    "id": "fxYk3rTMh2dt"
   },
   "source": [
    "*Robust Scaling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rkaU4ezuhnsS",
   "metadata": {
    "id": "rkaU4ezuhnsS"
   },
   "outputs": [],
   "source": [
    "# importing sklearn Min Max Scaler class which is for Robust scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rs = RobustScaler() # creating an instance of the class object\n",
    "X_tr_sc = rs.fit_transform(train_data1)\n",
    "train_data_scaled = pd.DataFrame(X_tr_sc, columns=train_data1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XcPgMrmZrWfI",
   "metadata": {
    "id": "XcPgMrmZrWfI"
   },
   "source": [
    "**Dropping Highly correlated and high VIF columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "qSBp_YwgdIWX",
   "metadata": {
    "id": "qSBp_YwgdIWX"
   },
   "outputs": [],
   "source": [
    "train_data_scaled1 = train_data_scaled.drop(['mvar20', 'mvar32', 'mvar10'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iWFHdAoBg9WJ",
   "metadata": {
    "id": "iWFHdAoBg9WJ"
   },
   "source": [
    "**Imputing NULL values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "HvjTeYEP8uqc",
   "metadata": {
    "id": "HvjTeYEP8uqc"
   },
   "outputs": [],
   "source": [
    "def new_col_for_null(df, column):\n",
    "  df[column+'_null'] = np.where(df[column].isnull(), 1, 0)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0826iy5W_C2h",
   "metadata": {
    "id": "0826iy5W_C2h"
   },
   "outputs": [],
   "source": [
    "for col in train_data_scaled1.columns:\n",
    "  new_col_for_null(train_data_scaled1, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50329e",
   "metadata": {
    "id": "6b50329e"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "imputed_1 = imputer.fit_transform(train_data_scaled1)\n",
    "train_data2 = pd.DataFrame(imputed_1, columns=train_data_scaled1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1_HV_G9L6SDb",
   "metadata": {
    "id": "1_HV_G9L6SDb"
   },
   "outputs": [],
   "source": [
    "train_data3 = train_data2.drop('mvar47_C', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154bkbd_y1q9",
   "metadata": {
    "id": "154bkbd_y1q9"
   },
   "outputs": [],
   "source": [
    "X = train_data3\n",
    "y = train_df['default_ind']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B4VyzLXBisbt",
   "metadata": {
    "id": "B4VyzLXBisbt"
   },
   "source": [
    "# **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q_90s5SH6b1t",
   "metadata": {
    "id": "q_90s5SH6b1t"
   },
   "source": [
    "#### **Dataset Balancing using SMOTETOMEK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rkrGtknVYlop",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkrGtknVYlop",
    "outputId": "6705205f-e49c-4677-d714-e442fb43d1de"
   },
   "outputs": [],
   "source": [
    "# Since our classes are highly skewed we should make them equivalent in order to have a normal \n",
    "# distribution of the classes.\n",
    "\n",
    "from imblearn.combine import SMOTETomek \n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_sampled1, Y_sampled1 = smt.fit_resample(X, y)\n",
    "\n",
    "X_sampled1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quLiCKhQztdG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quLiCKhQztdG",
    "outputId": "a823dd26-3750-48e0-c072-ec9d3cd9dfdd"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_sampled1, Y_sampled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3Y79HMuU8Fsd",
   "metadata": {
    "id": "3Y79HMuU8Fsd"
   },
   "outputs": [],
   "source": [
    "#Hyperparameter tuning of logistic regression\n",
    "\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# define models and parameters\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0)\n",
    "grid_result = grid_search.fit(X_sampled1, Y_sampled1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WrNsU4MbjqpR",
   "metadata": {
    "id": "WrNsU4MbjqpR"
   },
   "source": [
    "# **Working on COMPANY PROVIDED TEST DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_ZJY84h97erQ",
   "metadata": {
    "id": "_ZJY84h97erQ"
   },
   "outputs": [],
   "source": [
    "#Since we have combined certain columns, we need to drop those which are already considered in the combination.\n",
    "\n",
    "test_df3 = test_df2.drop(['mvar4', 'mvar5', 'mvar8', 'mvar17', 'mvar18', 'mvar27', 'mvar34', 'mvar46', \n",
    "                         'mvar48', 'mvar49'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sYLE9zDI7erR",
   "metadata": {
    "id": "sYLE9zDI7erR"
   },
   "outputs": [],
   "source": [
    "# dropping columns which have > 70% NULL values\n",
    "test_df3 = test_df3.drop(['mvar31', 'mvar40'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WPLn0HkE7erS",
   "metadata": {
    "id": "WPLn0HkE7erS"
   },
   "source": [
    "**Scaling and normalisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-ciDAQyG7erS",
   "metadata": {
    "id": "-ciDAQyG7erS"
   },
   "source": [
    "it is necessary because we will be using knn imputation as well as SMOTE for oversampling, which is also based on KNN methodology. For this reason, we need to scale the data so that higher magnitudes don't led to formation of clusters when using KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-GT-1A4G7erS",
   "metadata": {
    "id": "-GT-1A4G7erS"
   },
   "source": [
    "*Standardization*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zc_qQFjU7erS",
   "metadata": {
    "id": "zc_qQFjU7erS"
   },
   "outputs": [],
   "source": [
    "# importing sklearn StandardScaler class which is for Standardization\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sc = StandardScaler() # creating an instance of the class object\n",
    "#df_scaled = pd.DataFrame(sc.fit_transform(train_df4), columns=train_df4.columns)  #fit and transforming StandardScaler the dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sRuqPlWc7erT",
   "metadata": {
    "id": "sRuqPlWc7erT"
   },
   "source": [
    "*Robust Scaling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OSV1h2ED7erT",
   "metadata": {
    "id": "OSV1h2ED7erT"
   },
   "outputs": [],
   "source": [
    "# importing sklearn Min Max Scaler class which is for Robust scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rs = RobustScaler() # creating an instance of the class object\n",
    "sc = rs.fit_transform(test_df3)\n",
    "scaled_test = pd.DataFrame(sc, columns=test_df3.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1rMQEo1n7erV",
   "metadata": {
    "id": "1rMQEo1n7erV"
   },
   "source": [
    "**Dropping Highly correlated and high VIF columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74xo0YPU7erV",
   "metadata": {
    "id": "74xo0YPU7erV"
   },
   "outputs": [],
   "source": [
    "scaled_test1 = scaled_test.drop(['mvar20', 'mvar32', 'mvar10'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_gaENGbBYX5Q",
   "metadata": {
    "id": "_gaENGbBYX5Q"
   },
   "outputs": [],
   "source": [
    "def new_col_for_null(df, column):\n",
    "  df[column+'_null'] = np.where(df[column].isnull(), 1, 0)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CIvaewikYX5Q",
   "metadata": {
    "id": "CIvaewikYX5Q"
   },
   "outputs": [],
   "source": [
    "for col in scaled_test1.columns:\n",
    "  new_col_for_null(scaled_test1, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "se109jwU7erV",
   "metadata": {
    "id": "se109jwU7erV"
   },
   "source": [
    "**Imputing NULL values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dAaoy0AJ7erV",
   "metadata": {
    "id": "dAaoy0AJ7erV"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "imputed = imputer.fit_transform(scaled_test1)\n",
    "test_df4 = pd.DataFrame(imputed, columns=scaled_test1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H9ploMZ4zBEQ",
   "metadata": {
    "id": "H9ploMZ4zBEQ"
   },
   "outputs": [],
   "source": [
    "test_df4 = test_df4.drop('mvar47_C', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q-wgMLF91czJ",
   "metadata": {
    "id": "q-wgMLF91czJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e61ed9",
   "metadata": {
    "id": "62e61ed9"
   },
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "X_test = test_df4\n",
    "y_pred = grid_result.predict(test_df4)\n",
    "\n",
    "new = pd.DataFrame(y_pred, columns=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RY3Vt8bY9rm3",
   "metadata": {
    "id": "RY3Vt8bY9rm3"
   },
   "outputs": [],
   "source": [
    "new.insert(0, \"application_key\", test_df['application_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w2_IMZ-9_9qm",
   "metadata": {
    "id": "w2_IMZ-9_9qm"
   },
   "outputs": [],
   "source": [
    "new = new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T-61vOiE9zf7",
   "metadata": {
    "id": "T-61vOiE9zf7"
   },
   "outputs": [],
   "source": [
    "new.to_csv('Daring_souls_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DowZI6pWY0dl",
   "metadata": {
    "id": "DowZI6pWY0dl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
